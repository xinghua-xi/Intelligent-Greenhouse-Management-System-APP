/**
 * è¯­éŸ³é—®ç­”åŠ©æ‰‹ç»„ä»¶ - æ”¯æŒè®¯é£è¯­éŸ³è¯†åˆ«
 */

import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  Modal,
  StyleSheet,
  ActivityIndicator,
  Alert,
  Animated,
  TextInput,
  KeyboardAvoidingView,
  Platform,
  ScrollView,
} from 'react-native';
import { Mic, X, Volume2, VolumeX, ChevronLeft, Send, MicOff } from 'lucide-react-native';
import { useTheme } from '../context/ThemeContext';
import { aiApi } from '../services/api';
import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system/legacy';

interface VoiceAssistantProps {
  visible: boolean;
  onClose: () => void;
}

const VoiceAssistant: React.FC<VoiceAssistantProps> = ({ visible, onClose }) => {
  const { colors, isDark } = useTheme();
  const [status, setStatus] = useState<'idle' | 'listening' | 'recognizing' | 'thinking' | 'speaking'>('idle');
  const [inputText, setInputText] = useState('');
  const [question, setQuestion] = useState('');
  const [answer, setAnswer] = useState('');
  const [pulseAnim] = useState(new Animated.Value(1));
  const recordingRef = useRef<Audio.Recording | null>(null);
  const [permissionGranted, setPermissionGranted] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);

  // å¿«æ·é—®é¢˜
  const quickQuestions = [
    'ç•ªèŒ„å¶å­å‘é»„æ€ä¹ˆåŠï¼Ÿ',
    'ä»Šå¤©éœ€è¦æµ‡æ°´å—ï¼Ÿ',
    'å¤§æ£šæ¸©åº¦å¤šå°‘åˆé€‚ï¼Ÿ',
    'å¦‚ä½•é˜²æ²»ç—…è™«å®³ï¼Ÿ',
  ];

  // è¯·æ±‚éº¦å…‹é£æƒé™
  useEffect(() => {
    (async () => {
      const { status } = await Audio.requestPermissionsAsync();
      setPermissionGranted(status === 'granted');
    })();
  }, []);

  // å½•éŸ³è®¡æ—¶å™¨
  useEffect(() => {
    let timer: NodeJS.Timeout;
    if (status === 'listening') {
      timer = setInterval(() => {
        setRecordingDuration(d => d + 1);
      }, 1000);
    } else {
      setRecordingDuration(0);
    }
    return () => clearInterval(timer);
  }, [status]);

  // è„‰å†²åŠ¨ç”»
  useEffect(() => {
    if (status === 'listening') {
      const pulse = Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, { toValue: 1.3, duration: 600, useNativeDriver: true }),
          Animated.timing(pulseAnim, { toValue: 1, duration: 600, useNativeDriver: true }),
        ])
      );
      pulse.start();
      return () => pulse.stop();
    } else {
      pulseAnim.setValue(1);
    }
  }, [status]);

  // å…³é—­æ—¶æ¸…ç†
  useEffect(() => {
    if (!visible) {
      Speech.stop();
      if (recordingRef.current) {
        recordingRef.current.stopAndUnloadAsync().catch(() => {});
        recordingRef.current = null;
      }
      setStatus('idle');
      setQuestion('');
      setAnswer('');
      setInputText('');
    }
  }, [visible]);

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    // é˜²æ­¢é‡å¤è°ƒç”¨
    if (status !== 'idle') return;

    try {
      // å…ˆæ£€æŸ¥æƒé™
      const { status: permStatus } = await Audio.requestPermissionsAsync();
      if (permStatus !== 'granted') {
        Alert.alert('éœ€è¦éº¦å…‹é£æƒé™', 'è¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£');
        return;
      }
      setPermissionGranted(true);

      // ç¡®ä¿ä¹‹å‰çš„å½•éŸ³å·²å®Œå…¨å¸è½½
      if (recordingRef.current) {
        try {
          await recordingRef.current.stopAndUnloadAsync();
        } catch {}
        recordingRef.current = null;
        // ç­‰å¾…ä¸€ä¸‹è®©ç³»ç»Ÿé‡Šæ”¾èµ„æº
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      // é‡ç½®éŸ³é¢‘æ¨¡å¼
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      // ä½¿ç”¨é¢„è®¾çš„é«˜è´¨é‡å½•éŸ³é€‰é¡¹
      const { recording: newRecording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );

      recordingRef.current = newRecording;
      setStatus('listening');
      setAnswer('');
      setQuestion('');

    } catch (err: any) {
      console.error('å½•éŸ³å¤±è´¥:', err);
      recordingRef.current = null;
      
      if (err.message?.includes('Only one Recording')) {
        // ç­‰å¾…åé‡è¯•
        await new Promise(resolve => setTimeout(resolve, 500));
        try {
          await Audio.setAudioModeAsync({
            allowsRecordingIOS: true,
            playsInSilentModeIOS: true,
          });
          const { recording: retryRecording } = await Audio.Recording.createAsync(
            Audio.RecordingOptionsPresets.HIGH_QUALITY
          );
          recordingRef.current = retryRecording;
          setStatus('listening');
          setAnswer('');
          setQuestion('');
        } catch (retryErr) {
          console.error('é‡è¯•å½•éŸ³å¤±è´¥:', retryErr);
          Alert.alert('å½•éŸ³å¤±è´¥', 'è¯·ç¨åé‡è¯•');
        }
      } else {
        Alert.alert('å½•éŸ³å¤±è´¥', 'æ— æ³•å¯åŠ¨å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
      }
    }
  };

  // åœæ­¢å½•éŸ³å¹¶è¯†åˆ«
  const stopRecording = async () => {
    if (!recordingRef.current || status !== 'listening') return;

    try {
      setStatus('recognizing');
      
      const currentRecording = recordingRef.current;
      recordingRef.current = null;
      
      await currentRecording.stopAndUnloadAsync();
      const uri = currentRecording.getURI();

      if (uri) {
        // è¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶è½¬ä¸º base64
        const base64Audio = await FileSystem.readAsStringAsync(uri, {
          encoding: 'base64',
        });

        // è·å–æ–‡ä»¶æ ¼å¼
        const format = uri.includes('.m4a') ? 'm4a' : 'wav';
        console.log('ğŸ¤ éŸ³é¢‘æ ¼å¼:', format, 'å¤§å°:', base64Audio.length);

        // è°ƒç”¨åç«¯è¯­éŸ³è¯†åˆ«æ¥å£
        try {
          const result = await aiApi.speechToText(base64Audio, format);
          
          if (result.text && result.text.trim()) {
            setInputText(result.text);
            // è‡ªåŠ¨å‘é€è¯†åˆ«ç»“æœ
            handleQuestion(result.text);
          } else {
            setStatus('idle');
            Alert.alert('è¯†åˆ«å¤±è´¥', 'æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·é‡è¯•æˆ–æ‰‹åŠ¨è¾“å…¥');
          }
        } catch (err: any) {
          console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
          setStatus('idle');
          Alert.alert('è¯†åˆ«å¤±è´¥', err.message || 'è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥');
        }

        // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        try {
          await FileSystem.deleteAsync(uri, { idempotent: true });
        } catch {}
      }
    } catch (err) {
      console.error('åœæ­¢å½•éŸ³å¤±è´¥:', err);
      setStatus('idle');
    }
  };

  // å¤„ç†é—®é¢˜
  const handleQuestion = async (q: string) => {
    if (!q.trim()) return;
    
    setQuestion(q);
    setInputText('');
    setStatus('thinking');

    try {
      const response = await aiApi.chat({ prompt: q });
      
      if (response.success) {
        setAnswer(response.text);
        setStatus('speaking');
        
        // æœ—è¯»å›ç­”
        Speech.speak(response.text, {
          language: 'zh-CN',
          pitch: 1.0,
          rate: 0.9,
          onDone: () => setStatus('idle'),
          onStopped: () => setStatus('idle'),
          onError: () => setStatus('idle'),
        });
      } else {
        throw new Error('AI å“åº”å¤±è´¥');
      }
    } catch (error: any) {
      setStatus('idle');
      Alert.alert('æç¤º', error.message || 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨');
    }
  };

  // åœæ­¢æœ—è¯»
  const stopSpeaking = () => {
    Speech.stop();
    setStatus('idle');
  };

  const getStatusText = () => {
    switch (status) {
      case 'listening': return `å½•éŸ³ä¸­... ${recordingDuration}ç§’`;
      case 'recognizing': return 'æ­£åœ¨è¯†åˆ«è¯­éŸ³...';
      case 'thinking': return 'æ€è€ƒä¸­...';
      case 'speaking': return 'æ­£åœ¨å›ç­”...';
      default: return 'æŒ‰ä½éº¦å…‹é£è¯´è¯';
    }
  };

  const getStatusColor = () => {
    switch (status) {
      case 'listening': return '#ef4444';
      case 'recognizing': return '#f59e0b';
      case 'thinking': return '#f59e0b';
      case 'speaking': return '#3b82f6';
      default: return '#10b981';
    }
  };

  return (
    <Modal visible={visible} animationType="slide" presentationStyle="pageSheet">
      <View style={[styles.container, { backgroundColor: colors.background }]}>
        {/* é¡¶éƒ¨å¯¼èˆªæ  */}
        <View style={[styles.header, { backgroundColor: colors.card, borderBottomColor: colors.border }]}>
          <TouchableOpacity style={styles.backButton} onPress={onClose}>
            <ChevronLeft size={28} color={colors.text} />
            <Text style={[styles.backText, { color: colors.text }]}>è¿”å›</Text>
          </TouchableOpacity>
          <View style={styles.headerRight}>
            {status === 'speaking' && (
              <TouchableOpacity onPress={stopSpeaking} style={styles.stopButton}>
                <VolumeX size={24} color="#ef4444" />
              </TouchableOpacity>
            )}
          </View>
        </View>

        <KeyboardAvoidingView 
          style={styles.content}
          behavior={Platform.OS === 'ios' ? 'padding' : undefined}
        >
          <ScrollView style={styles.scrollView} contentContainerStyle={styles.scrollContent}>
            {/* è¯­éŸ³æŒ‰é’®åŒºåŸŸ */}
            <View style={styles.micSection}>
              <Text style={[styles.statusText, { color: getStatusColor() }]}>
                {getStatusText()}
              </Text>
              
              <Animated.View style={[
                styles.micPulse,
                { transform: [{ scale: pulseAnim }] },
                status === 'listening' && styles.micPulseActive
              ]}>
                <TouchableOpacity
                  style={[
                    styles.micButton,
                    { backgroundColor: getStatusColor() }
                  ]}
                  onPressIn={status === 'idle' ? startRecording : undefined}
                  onPressOut={status === 'listening' ? stopRecording : undefined}
                  onPress={status === 'speaking' ? stopSpeaking : undefined}
                  disabled={status === 'thinking' || status === 'recognizing'}
                >
                  {(status === 'thinking' || status === 'recognizing') ? (
                    <ActivityIndicator size="large" color="#fff" />
                  ) : status === 'speaking' ? (
                    <Volume2 size={48} color="#fff" />
                  ) : status === 'listening' ? (
                    <MicOff size={48} color="#fff" />
                  ) : (
                    <Mic size={48} color="#fff" />
                  )}
                </TouchableOpacity>
              </Animated.View>
              
              <Text style={[styles.micHint, { color: colors.textMuted }]}>
                {status === 'listening' ? 'æ¾å¼€ç»“æŸå½•éŸ³' : 
                 status === 'speaking' ? 'ç‚¹å‡»åœæ­¢æœ—è¯»' : 'æŒ‰ä½è¯´è¯'}
              </Text>
            </View>

            {/* å¿«æ·é—®é¢˜ */}
            {!question && status === 'idle' && (
              <View style={styles.quickSection}>
                <Text style={[styles.quickTitle, { color: colors.textMuted }]}>æˆ–é€‰æ‹©å¿«æ·é—®é¢˜</Text>
                <View style={styles.quickGrid}>
                  {quickQuestions.map((q, i) => (
                    <TouchableOpacity
                      key={i}
                      style={[styles.quickButton, { backgroundColor: colors.card, borderColor: colors.border }]}
                      onPress={() => handleQuestion(q)}
                    >
                      <Text style={[styles.quickText, { color: colors.text }]}>{q}</Text>
                    </TouchableOpacity>
                  ))}
                </View>
              </View>
            )}

            {/* é—®é¢˜æ˜¾ç¤º */}
            {question && (
              <View style={[styles.questionBox, { backgroundColor: isDark ? colors.border : '#e0f2fe' }]}>
                <Text style={[styles.boxLabel, { color: colors.textMuted }]}>æ‚¨çš„é—®é¢˜</Text>
                <Text style={[styles.questionText, { color: colors.text }]}>{question}</Text>
              </View>
            )}

            {/* å›ç­”æ˜¾ç¤º */}
            {answer && (
              <View style={[styles.answerBox, { backgroundColor: isDark ? 'rgba(16, 185, 129, 0.15)' : '#ecfdf5' }]}>
                <View style={styles.answerHeader}>
                  <Volume2 size={18} color="#10b981" />
                  <Text style={styles.answerLabel}>AI å›ç­”</Text>
                  {status === 'speaking' && (
                    <View style={styles.speakingIndicator}>
                      <Text style={styles.speakingText}>æœ—è¯»ä¸­</Text>
                    </View>
                  )}
                </View>
                <Text style={[styles.answerText, { color: colors.text }]}>{answer}</Text>
                
                {status === 'idle' && (
                  <TouchableOpacity 
                    style={styles.replayButton}
                    onPress={() => {
                      setStatus('speaking');
                      Speech.speak(answer, {
                        language: 'zh-CN',
                        pitch: 1.0,
                        rate: 0.9,
                        onDone: () => setStatus('idle'),
                        onStopped: () => setStatus('idle'),
                      });
                    }}
                  >
                    <Volume2 size={16} color="#10b981" />
                    <Text style={styles.replayText}>é‡æ–°æœ—è¯»</Text>
                  </TouchableOpacity>
                )}
              </View>
            )}
          </ScrollView>

          {/* åº•éƒ¨è¾“å…¥åŒºåŸŸ */}
          <View style={[styles.inputContainer, { backgroundColor: colors.card, borderTopColor: colors.border }]}>
            <View style={[styles.inputWrapper, { backgroundColor: isDark ? colors.border : '#f3f4f6' }]}>
              <TextInput
                style={[styles.input, { color: colors.text }]}
                placeholder="æˆ–åœ¨è¿™é‡Œè¾“å…¥é—®é¢˜..."
                placeholderTextColor={colors.textMuted}
                value={inputText}
                onChangeText={setInputText}
                multiline
                maxLength={200}
                editable={status === 'idle'}
              />
            </View>
            <TouchableOpacity
              style={[styles.sendButton, (!inputText.trim() || status !== 'idle') && styles.sendButtonDisabled]}
              onPress={() => handleQuestion(inputText)}
              disabled={!inputText.trim() || status !== 'idle'}
            >
              <Send size={20} color="#fff" />
            </TouchableOpacity>
          </View>
        </KeyboardAvoidingView>
      </View>
    </Modal>
  );
};

const styles = StyleSheet.create({
  container: { flex: 1 },
  header: { 
    flexDirection: 'row', 
    alignItems: 'center', 
    justifyContent: 'space-between',
    paddingHorizontal: 12, 
    paddingTop: 50,
    paddingBottom: 12,
    borderBottomWidth: 1,
  },
  backButton: { flexDirection: 'row', alignItems: 'center', padding: 4 },
  backText: { fontSize: 17, marginLeft: 4 },
  headerRight: { width: 60, alignItems: 'flex-end' },
  stopButton: { padding: 8 },
  content: { flex: 1 },
  scrollView: { flex: 1 },
  scrollContent: { padding: 20, paddingBottom: 20 },
  micSection: { alignItems: 'center', marginVertical: 20 },
  statusText: { fontSize: 18, fontWeight: '600', marginBottom: 24 },
  micPulse: { borderRadius: 80 },
  micPulseActive: { backgroundColor: 'rgba(239, 68, 68, 0.2)' },
  micButton: {
    width: 140,
    height: 140,
    borderRadius: 70,
    alignItems: 'center',
    justifyContent: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 6 },
    shadowOpacity: 0.3,
    shadowRadius: 12,
    elevation: 10,
  },
  micHint: { marginTop: 20, fontSize: 15 },
  quickSection: { marginTop: 30 },
  quickTitle: { fontSize: 14, marginBottom: 16, textAlign: 'center' },
  quickGrid: { gap: 12 },
  quickButton: { 
    paddingHorizontal: 20, 
    paddingVertical: 18, 
    borderRadius: 16, 
    borderWidth: 1,
  },
  quickText: { fontSize: 17, textAlign: 'center' },
  questionBox: { 
    padding: 20, 
    borderRadius: 20, 
    marginTop: 24,
  },
  boxLabel: { fontSize: 13, marginBottom: 8 },
  questionText: { fontSize: 18, fontWeight: '600', lineHeight: 28 },
  answerBox: { 
    padding: 20, 
    borderRadius: 20, 
    marginTop: 16,
  },
  answerHeader: { 
    flexDirection: 'row', 
    alignItems: 'center', 
    gap: 8, 
    marginBottom: 12,
  },
  answerLabel: { fontSize: 15, color: '#10b981', fontWeight: '600' },
  speakingIndicator: { 
    backgroundColor: '#10b981', 
    paddingHorizontal: 10, 
    paddingVertical: 4, 
    borderRadius: 12,
    marginLeft: 'auto',
  },
  speakingText: { color: '#fff', fontSize: 11, fontWeight: 'bold' },
  answerText: { fontSize: 17, lineHeight: 28 },
  replayButton: { 
    flexDirection: 'row', 
    alignItems: 'center', 
    gap: 6, 
    marginTop: 16,
    alignSelf: 'flex-start',
    paddingVertical: 8,
  },
  replayText: { color: '#10b981', fontSize: 15, fontWeight: '500' },
  inputContainer: { 
    flexDirection: 'row', 
    alignItems: 'flex-end', 
    padding: 12, 
    borderTopWidth: 1, 
    gap: 10,
  },
  inputWrapper: { 
    flex: 1, 
    borderRadius: 24, 
    paddingHorizontal: 18, 
    paddingVertical: 12,
    maxHeight: 100,
  },
  input: { fontSize: 16, maxHeight: 80 },
  sendButton: { 
    width: 50, 
    height: 50, 
    borderRadius: 25, 
    backgroundColor: '#10b981', 
    alignItems: 'center', 
    justifyContent: 'center',
  },
  sendButtonDisabled: { backgroundColor: '#9ca3af' },
});

export default VoiceAssistant;

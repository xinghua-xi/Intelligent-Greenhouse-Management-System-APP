/**
 * AI æ™ºèƒ½é—®ç­”é¡µé¢
 */

import React, { useState, useRef, useEffect } from 'react';
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  ScrollView,
  StyleSheet,
  KeyboardAvoidingView,
  Platform,
  ActivityIndicator,
  Alert,
  Animated,
} from 'react-native';
import { SafeAreaView } from 'react-native-safe-area-context';
import { useNavigation } from '@react-navigation/native';
import { ChevronLeft, Send, Mic, MicOff, Bot, User, Trash2, Volume2, VolumeX } from 'lucide-react-native';
import { useTheme } from '../context/ThemeContext';
import { aiApi } from '../services/api';
import { ChatMessage } from '../services/api/types';
import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system/legacy';

const AiChat: React.FC = () => {
  const navigation = useNavigation<any>();
  const { colors, isDark } = useTheme();
  const scrollViewRef = useRef<ScrollView>(null);
  
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [autoSpeak, setAutoSpeak] = useState(true); // è‡ªåŠ¨æœ—è¯»å¼€å…³
  
  // è¯­éŸ³å½•åˆ¶ç›¸å…³
  const recordingRef = useRef<Audio.Recording | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isRecognizing, setIsRecognizing] = useState(false);
  const [permissionGranted, setPermissionGranted] = useState(false);
  const [pulseAnim] = useState(new Animated.Value(1));

  // å¿«æ·é—®é¢˜
  const quickQuestions = [
    'ç•ªèŒ„å¶å­å‘é»„æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ',
    'ä»Šå¤©éœ€è¦æµ‡æ°´å—ï¼Ÿ',
    'å¦‚ä½•é˜²æ²»çº¢èœ˜è››ï¼Ÿ',
    'å¤§æ£šæ¸©åº¦å¤šå°‘åˆé€‚ï¼Ÿ',
  ];

  // è¯·æ±‚éº¦å…‹é£æƒé™
  useEffect(() => {
    (async () => {
      const { status } = await Audio.requestPermissionsAsync();
      setPermissionGranted(status === 'granted');
    })();
  }, []);

  // è„‰å†²åŠ¨ç”»
  useEffect(() => {
    if (isRecording) {
      const pulse = Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, { toValue: 1.2, duration: 500, useNativeDriver: true }),
          Animated.timing(pulseAnim, { toValue: 1, duration: 500, useNativeDriver: true }),
        ])
      );
      pulse.start();
      return () => pulse.stop();
    } else {
      pulseAnim.setValue(1);
    }
  }, [isRecording]);

  // åœæ­¢æœ—è¯»
  useEffect(() => {
    return () => {
      Speech.stop();
      if (recordingRef.current) {
        recordingRef.current.stopAndUnloadAsync().catch(() => {});
      }
    };
  }, []);

  // æœ—è¯»æ–‡æœ¬
  const speakText = async (text: string) => {
    try {
      // å…ˆåœæ­¢ä¹‹å‰çš„æœ—è¯»
      await Speech.stop();
      setIsSpeaking(true);
      
      await Speech.speak(text, {
        language: 'zh-CN',
        pitch: 1.0,
        rate: 0.9,
        onDone: () => setIsSpeaking(false),
        onStopped: () => setIsSpeaking(false),
        onError: () => setIsSpeaking(false),
      });
    } catch (error) {
      console.error('è¯­éŸ³åˆæˆå¤±è´¥:', error);
      setIsSpeaking(false);
    }
  };

  // åœæ­¢æœ—è¯»
  const stopSpeaking = async () => {
    await Speech.stop();
    setIsSpeaking(false);
  };

  // å‘é€æ¶ˆæ¯
  const sendMessage = async (text: string) => {
    if (!text.trim() || loading) return;

    const userMessage: ChatMessage = { role: 'user', content: text.trim() };
    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setLoading(true);

    // æ»šåŠ¨åˆ°åº•éƒ¨
    setTimeout(() => scrollViewRef.current?.scrollToEnd({ animated: true }), 100);

    try {
      const response = await aiApi.chat({
        prompt: text.trim(),
        history: messages.slice(-10), // æœ€è¿‘10æ¡å†å²
      });

      if (response.success) {
        const assistantMessage: ChatMessage = { role: 'assistant', content: response.text };
        setMessages(prev => [...prev, assistantMessage]);
        
        // è‡ªåŠ¨æœ—è¯»å›ç­”
        if (autoSpeak) {
          speakText(response.text);
        }
      } else {
        throw new Error('AI å“åº”å¤±è´¥');
      }
    } catch (error: any) {
      console.error('é—®ç­”å¤±è´¥:', error);
      Alert.alert('æç¤º', error.message || 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•');
      // ç§»é™¤ç”¨æˆ·æ¶ˆæ¯
      setMessages(prev => prev.slice(0, -1));
    } finally {
      setLoading(false);
      setTimeout(() => scrollViewRef.current?.scrollToEnd({ animated: true }), 100);
    }
  };

  // è¯­éŸ³è¾“å…¥æç¤º
  const showVoiceInputTip = () => {
    Alert.alert(
      'è¯­éŸ³è¾“å…¥',
      'è¯·ä½¿ç”¨ç³»ç»Ÿé”®ç›˜çš„è¯­éŸ³è¾“å…¥åŠŸèƒ½ï¼š\n\n' +
      'â€¢ Android: ç‚¹å‡»é”®ç›˜ä¸Šçš„éº¦å…‹é£å›¾æ ‡\n' +
      'â€¢ iOS: é•¿æŒ‰ç©ºæ ¼é”®å¯åŠ¨å¬å†™\n\n' +
      'è¯­éŸ³è¯†åˆ«åæ–‡å­—ä¼šè‡ªåŠ¨å¡«å…¥è¾“å…¥æ¡†',
      [{ text: 'çŸ¥é“äº†' }]
    );
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    // é˜²æ­¢é‡å¤è°ƒç”¨
    if (isRecording || isRecognizing) return;

    try {
      // å…ˆæ£€æŸ¥æƒé™
      const { status } = await Audio.requestPermissionsAsync();
      if (status !== 'granted') {
        Alert.alert('éœ€è¦éº¦å…‹é£æƒé™', 'è¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£');
        return;
      }
      setPermissionGranted(true);

      // ç¡®ä¿ä¹‹å‰çš„å½•éŸ³å·²å®Œå…¨å¸è½½
      if (recordingRef.current) {
        try {
          await recordingRef.current.stopAndUnloadAsync();
        } catch {}
        recordingRef.current = null;
        // ç­‰å¾…ä¸€ä¸‹è®©ç³»ç»Ÿé‡Šæ”¾èµ„æº
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      // é‡ç½®éŸ³é¢‘æ¨¡å¼
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording: newRecording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );

      recordingRef.current = newRecording;
      setIsRecording(true);
    } catch (err: any) {
      console.error('å½•éŸ³å¤±è´¥:', err);
      recordingRef.current = null;
      setIsRecording(false);
      
      if (err.message?.includes('Only one Recording')) {
        // ç­‰å¾…åé‡è¯•
        await new Promise(resolve => setTimeout(resolve, 500));
        try {
          await Audio.setAudioModeAsync({
            allowsRecordingIOS: true,
            playsInSilentModeIOS: true,
          });
          const { recording: retryRecording } = await Audio.Recording.createAsync(
            Audio.RecordingOptionsPresets.HIGH_QUALITY
          );
          recordingRef.current = retryRecording;
          setIsRecording(true);
        } catch (retryErr) {
          console.error('é‡è¯•å½•éŸ³å¤±è´¥:', retryErr);
          Alert.alert('å½•éŸ³å¤±è´¥', 'è¯·ç¨åé‡è¯•');
        }
      } else {
        Alert.alert('å½•éŸ³å¤±è´¥', 'æ— æ³•å¯åŠ¨å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
      }
    }
  };

  // åœæ­¢å½•éŸ³å¹¶è¯†åˆ«
  const stopRecording = async () => {
    if (!recordingRef.current || !isRecording) return;

    try {
      setIsRecording(false);
      setIsRecognizing(true);
      
      const currentRecording = recordingRef.current;
      recordingRef.current = null;
      
      await currentRecording.stopAndUnloadAsync();
      const uri = currentRecording.getURI();

      if (uri) {
        const base64Audio = await FileSystem.readAsStringAsync(uri, {
          encoding: 'base64',
        });

        const format = uri.includes('.m4a') ? 'm4a' : 'wav';
        console.log('ğŸ¤ éŸ³é¢‘æ ¼å¼:', format, 'å¤§å°:', base64Audio.length);

        try {
          const result = await aiApi.speechToText(base64Audio, format);
          
          if (result.text && result.text.trim()) {
            setInputText(prev => prev + result.text);
          } else {
            Alert.alert('è¯†åˆ«å¤±è´¥', 'æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·é‡è¯•');
          }
        } catch (err: any) {
          console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
          Alert.alert('è¯†åˆ«å¤±è´¥', err.message || 'è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨');
        }

        try {
          await FileSystem.deleteAsync(uri, { idempotent: true });
        } catch {}
      }
    } catch (err) {
      console.error('åœæ­¢å½•éŸ³å¤±è´¥:', err);
    } finally {
      setIsRecognizing(false);
    }
  };

  // æ¸…ç©ºå¯¹è¯
  const clearChat = () => {
    Alert.alert('ç¡®è®¤', 'ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰å¯¹è¯å—ï¼Ÿ', [
      { text: 'å–æ¶ˆ', style: 'cancel' },
      { 
        text: 'ç¡®å®š', 
        onPress: () => {
          Speech.stop();
          setMessages([]);
        }
      },
    ]);
  };

  // åˆ‡æ¢è‡ªåŠ¨æœ—è¯»
  const toggleAutoSpeak = () => {
    if (autoSpeak) {
      Speech.stop();
      setIsSpeaking(false);
    }
    setAutoSpeak(!autoSpeak);
  };

  return (
    <View style={[styles.container, { backgroundColor: colors.background }]}>
      <SafeAreaView edges={['top']} style={[styles.header, { backgroundColor: colors.card, borderBottomColor: colors.border }]}>
        <View style={styles.headerContent}>
          <TouchableOpacity onPress={() => navigation.goBack()} style={styles.backButton}>
            <ChevronLeft size={24} color={colors.text} />
          </TouchableOpacity>
          <View style={styles.headerCenter}>
            <Text style={[styles.headerTitle, { color: colors.text }]}>AI æ™ºèƒ½é—®ç­”</Text>
            <Text style={[styles.headerSubtitle, { color: colors.textMuted }]}>DeepSeek å¤§æ¨¡å‹</Text>
          </View>
          <TouchableOpacity onPress={toggleAutoSpeak} style={styles.speakButton}>
            {autoSpeak ? (
              <Volume2 size={20} color="#10b981" />
            ) : (
              <VolumeX size={20} color={colors.textMuted} />
            )}
          </TouchableOpacity>
          <TouchableOpacity onPress={clearChat} style={styles.clearButton}>
            <Trash2 size={20} color={colors.textMuted} />
          </TouchableOpacity>
        </View>
      </SafeAreaView>

      <KeyboardAvoidingView 
        style={styles.chatContainer}
        behavior={Platform.OS === 'ios' ? 'padding' : undefined}
        keyboardVerticalOffset={Platform.OS === 'ios' ? 0 : 0}
      >
        <ScrollView
          ref={scrollViewRef}
          style={styles.messagesContainer}
          contentContainerStyle={styles.messagesContent}
          onContentSizeChange={() => scrollViewRef.current?.scrollToEnd({ animated: true })}
        >
          {/* æ¬¢è¿æ¶ˆæ¯ */}
          {messages.length === 0 && (
            <View style={styles.welcomeContainer}>
              <View style={[styles.welcomeIcon, { backgroundColor: isDark ? 'rgba(16, 185, 129, 0.2)' : '#ecfdf5' }]}>
                <Bot size={32} color="#10b981" />
              </View>
              <Text style={[styles.welcomeTitle, { color: colors.text }]}>ä½ å¥½ï¼Œæˆ‘æ˜¯ç»¿æ™ºåŠ©æ‰‹</Text>
              <Text style={[styles.welcomeDesc, { color: colors.textMuted }]}>
                æˆ‘å¯ä»¥å›ç­”å…³äºæ¸©å®¤ç§æ¤ã€ç—…è™«å®³é˜²æ²»ã€ç¯å¢ƒè°ƒæ§ç­‰é—®é¢˜
              </Text>
              
              {/* å¿«æ·é—®é¢˜ */}
              <View style={styles.quickQuestions}>
                <Text style={[styles.quickTitle, { color: colors.textMuted }]}>è¯•è¯•é—®æˆ‘ï¼š</Text>
                {quickQuestions.map((q, i) => (
                  <TouchableOpacity
                    key={i}
                    style={[styles.quickButton, { backgroundColor: colors.card, borderColor: colors.border }]}
                    onPress={() => sendMessage(q)}
                  >
                    <Text style={[styles.quickText, { color: colors.textSecondary }]}>{q}</Text>
                  </TouchableOpacity>
                ))}
              </View>
            </View>
          )}

          {/* æ¶ˆæ¯åˆ—è¡¨ */}
          {messages.map((msg, index) => (
            <View
              key={index}
              style={[
                styles.messageRow,
                msg.role === 'user' ? styles.messageRowUser : styles.messageRowAssistant,
              ]}
            >
              {msg.role === 'assistant' && (
                <View style={[styles.avatar, styles.avatarAssistant]}>
                  <Bot size={16} color="#fff" />
                </View>
              )}
              <TouchableOpacity
                style={[
                  styles.messageBubble,
                  msg.role === 'user'
                    ? [styles.bubbleUser, { backgroundColor: '#10b981' }]
                    : [styles.bubbleAssistant, { backgroundColor: colors.card, borderColor: colors.border }],
                ]}
                onPress={() => msg.role === 'assistant' && speakText(msg.content)}
                activeOpacity={msg.role === 'assistant' ? 0.7 : 1}
              >
                <Text
                  style={[
                    styles.messageText,
                    msg.role === 'user' ? styles.textUser : { color: colors.text },
                  ]}
                >
                  {msg.content}
                </Text>
                {msg.role === 'assistant' && (
                  <View style={styles.speakHint}>
                    <Volume2 size={12} color={colors.textMuted} />
                    <Text style={[styles.speakHintText, { color: colors.textMuted }]}>ç‚¹å‡»æœ—è¯»</Text>
                  </View>
                )}
              </TouchableOpacity>
              {msg.role === 'user' && (
                <View style={[styles.avatar, styles.avatarUser]}>
                  <User size={16} color="#fff" />
                </View>
              )}
            </View>
          ))}

          {/* åŠ è½½ä¸­ */}
          {loading && (
            <View style={[styles.messageRow, styles.messageRowAssistant]}>
              <View style={[styles.avatar, styles.avatarAssistant]}>
                <Bot size={16} color="#fff" />
              </View>
              <View style={[styles.messageBubble, styles.bubbleAssistant, { backgroundColor: colors.card, borderColor: colors.border }]}>
                <View style={styles.loadingDots}>
                  <ActivityIndicator size="small" color="#10b981" />
                  <Text style={[styles.loadingText, { color: colors.textMuted }]}>æ€è€ƒä¸­...</Text>
                </View>
              </View>
            </View>
          )}
        </ScrollView>

        {/* è¾“å…¥åŒºåŸŸ */}
        <View style={[styles.inputContainer, { backgroundColor: colors.card, borderTopColor: colors.border }]}>
          <View style={[styles.inputWrapper, { backgroundColor: isDark ? colors.border : '#f3f4f6' }]}>
            <TextInput
              style={[styles.input, { color: colors.text }]}
              placeholder={isRecording ? 'æ­£åœ¨å½•éŸ³...' : isRecognizing ? 'è¯†åˆ«ä¸­...' : 'è¾“å…¥ä½ çš„é—®é¢˜...'}
              placeholderTextColor={isRecording ? '#ef4444' : colors.textMuted}
              value={inputText}
              onChangeText={setInputText}
              multiline
              maxLength={500}
              editable={!loading && !isRecording && !isRecognizing}
            />
          </View>
          
          {/* è¯­éŸ³è¾“å…¥æŒ‰é’® */}
          <Animated.View style={{ transform: [{ scale: pulseAnim }] }}>
            <TouchableOpacity
              style={[
                styles.voiceButton, 
                { backgroundColor: isRecording ? '#ef4444' : isRecognizing ? '#f59e0b' : (isDark ? colors.border : '#f3f4f6') }
              ]}
              onPress={() => {
                if (isRecording) {
                  stopRecording();
                } else if (!isRecognizing && !loading) {
                  startRecording();
                }
              }}
              disabled={loading || isRecognizing}
            >
              {isRecognizing ? (
                <ActivityIndicator size="small" color="#fff" />
              ) : isRecording ? (
                <MicOff size={20} color="#fff" />
              ) : (
                <Mic size={20} color={isDark ? colors.textMuted : '#6b7280'} />
              )}
            </TouchableOpacity>
          </Animated.View>

          {/* åœæ­¢æœ—è¯»æŒ‰é’®ï¼ˆæœ—è¯»æ—¶æ˜¾ç¤ºï¼‰ */}
          {isSpeaking && (
            <TouchableOpacity
              style={[styles.stopButton]}
              onPress={stopSpeaking}
            >
              <VolumeX size={20} color="#fff" />
            </TouchableOpacity>
          )}

          {/* å‘é€æŒ‰é’® */}
          <TouchableOpacity
            style={[styles.sendButton, (!inputText.trim() || loading || isRecording || isRecognizing) && styles.sendButtonDisabled]}
            onPress={() => sendMessage(inputText)}
            disabled={!inputText.trim() || loading || isRecording || isRecognizing}
          >
            <Send size={20} color="#fff" />
          </TouchableOpacity>
        </View>
      </KeyboardAvoidingView>
    </View>
  );
};

const styles = StyleSheet.create({
  container: { flex: 1 },
  header: { borderBottomWidth: 1 },
  headerContent: { flexDirection: 'row', alignItems: 'center', paddingHorizontal: 16, paddingVertical: 12 },
  backButton: { padding: 4 },
  headerCenter: { flex: 1, marginLeft: 12 },
  headerTitle: { fontSize: 18, fontWeight: 'bold' },
  headerSubtitle: { fontSize: 12, marginTop: 2 },
  speakButton: { padding: 8, marginRight: 4 },
  clearButton: { padding: 8 },
  chatContainer: { flex: 1 },
  messagesContainer: { flex: 1 },
  messagesContent: { padding: 16, paddingBottom: 20 },
  welcomeContainer: { alignItems: 'center', paddingVertical: 40 },
  welcomeIcon: { width: 72, height: 72, borderRadius: 36, alignItems: 'center', justifyContent: 'center', marginBottom: 16 },
  welcomeTitle: { fontSize: 20, fontWeight: 'bold', marginBottom: 8 },
  welcomeDesc: { fontSize: 14, textAlign: 'center', paddingHorizontal: 32, lineHeight: 20 },
  quickQuestions: { marginTop: 32, width: '100%' },
  quickTitle: { fontSize: 12, marginBottom: 12, textAlign: 'center' },
  quickButton: { paddingHorizontal: 16, paddingVertical: 12, borderRadius: 12, borderWidth: 1, marginBottom: 8 },
  quickText: { fontSize: 14 },
  messageRow: { flexDirection: 'row', marginBottom: 16, alignItems: 'flex-end' },
  messageRowUser: { justifyContent: 'flex-end' },
  messageRowAssistant: { justifyContent: 'flex-start' },
  avatar: { width: 32, height: 32, borderRadius: 16, alignItems: 'center', justifyContent: 'center' },
  avatarUser: { backgroundColor: '#3b82f6', marginLeft: 8 },
  avatarAssistant: { backgroundColor: '#10b981', marginRight: 8 },
  messageBubble: { maxWidth: '75%', paddingHorizontal: 16, paddingVertical: 12, borderRadius: 20 },
  bubbleUser: { borderBottomRightRadius: 4 },
  bubbleAssistant: { borderBottomLeftRadius: 4, borderWidth: 1 },
  messageText: { fontSize: 15, lineHeight: 22 },
  textUser: { color: '#fff' },
  speakHint: { flexDirection: 'row', alignItems: 'center', gap: 4, marginTop: 8, opacity: 0.6 },
  speakHintText: { fontSize: 10 },
  loadingDots: { flexDirection: 'row', alignItems: 'center', gap: 8 },
  loadingText: { fontSize: 14 },
  inputContainer: { flexDirection: 'row', alignItems: 'flex-end', padding: 12, borderTopWidth: 1, gap: 8 },
  inputWrapper: { flex: 1, borderRadius: 24, paddingHorizontal: 16, paddingVertical: 8, maxHeight: 120 },
  input: { fontSize: 15, maxHeight: 100 },
  voiceButton: { width: 44, height: 44, borderRadius: 22, alignItems: 'center', justifyContent: 'center' },
  stopButton: { width: 44, height: 44, borderRadius: 22, backgroundColor: '#ef4444', alignItems: 'center', justifyContent: 'center' },
  sendButton: { width: 44, height: 44, borderRadius: 22, backgroundColor: '#10b981', alignItems: 'center', justifyContent: 'center' },
  sendButtonDisabled: { backgroundColor: '#9ca3af' },
});

export default AiChat;
